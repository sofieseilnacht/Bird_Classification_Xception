{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LkAt4xhuz2TP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.xception import preprocess_input\n",
        "from tensorflow.keras import callbacks\n",
        "import keras\n",
        "import keras_tuner\n",
        "import keras.utils as image\n",
        "from keras import layers\n",
        "from keras import ops\n",
        "from keras import callbacks\n",
        "from keras import regularizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49L3SjdWR8Oa"
      },
      "source": [
        "## Importing Data from csv files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6Q84PvEJobQu",
        "outputId": "bc83029b-8453-4423-d0da-4b8bab6425dd"
      },
      "outputs": [],
      "source": [
        "images = pd.read_csv(\"/Users/sofie/Desktop/Projects/Classification of Birds/CUB_200_2011/images.txt\", sep=r'\\s+', names=['image_id', 'image_name'], engine='python')\n",
        "train_test_split = pd.read_csv(\"/Users/sofie/Desktop/Projects/Classification of Birds/CUB_200_2011/train_test_split.txt\", sep=r'\\s+', names=['image_id', 'is_training_image'], engine='python')\n",
        "classes =pd.read_csv(\"/Users/sofie/Desktop/Projects/Classification of Birds/CUB_200_2011/classes.txt\", sep=r'\\s+', names=['class_id', 'class_name'], engine='python')\n",
        "image_class_labels =pd.read_csv(\"/Users/sofie/Desktop/Projects/Classification of Birds/CUB_200_2011/image_class_labels.txt\", sep=r'\\s+', names=['image_id', 'class_id'], engine='python')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay9R_UOcSKkH"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Rj27i5GRKG1",
        "outputId": "74981fbd-a7de-43a8-8ffd-76dab7ec4c11"
      },
      "outputs": [],
      "source": [
        "# Merge dfs based on column names so we have one df with all the necessary info contained per each row\n",
        "image_data = pd.merge(images,train_test_split, on='image_id')\n",
        "image_data = pd.merge(image_data,image_class_labels, on='image_id')\n",
        "image_data = pd.merge(image_data,classes, on='class_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split training and testing image data\n",
        "training_image_data = image_data[image_data['is_training_image']==1]\n",
        "testing_image_data = image_data[image_data['is_training_image']==0]\n",
        "\n",
        "# Shuffle training data\n",
        "training_image_data = training_image_data.sample(frac=1)\n",
        "\n",
        "# Initiate empty lists for training and testing images\n",
        "training_images = []\n",
        "testing_images = []\n",
        "\n",
        "# Add training and testing images to corresponding lists\n",
        "for i in (training_image_data['image_name'].values):\n",
        "    training_images.append(image.load_img('/Users/sofie/Desktop/Projects/Classification of Birds/CUB_200_2011/images/{}'.format(i), target_size=(224, 224)))\n",
        "\n",
        "for i in (testing_image_data['image_name'].values):\n",
        "    testing_images.append(image.load_img('/Users/sofie/Desktop/Projects/Classification of Birds/CUB_200_2011/images/{}'.format(i), target_size=(224, 224)))\n",
        "\n",
        "# Extract class labels for training and testing images\n",
        "training_class_label = np.array(training_image_data['class_id'].values)\n",
        "testing_class_label = np.array(testing_image_data['class_id'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert list of images to NumPy array\n",
        "training_images = np.array(training_images)\n",
        "testing_images = np.array(testing_images)\n",
        "\n",
        "# Apply preprocessing\n",
        "preprocessed_training_images = preprocess_input(training_images)\n",
        "preprocessed_testing_images = preprocess_input(testing_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We begin training by keeping the existing layers frozen, allowing only the newly added classification head to learn. This ensures that the output layer is properly trained before fine-tuning the deeper layers. Once the classifier stabilizes, we gradually unfreeze and fine-tune the earlier layers, optimizing them in a controlled manner. This approach prevents instability in feature extraction and allows each layer to adjust effectively, improving overall model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4195 4195\n",
            "1799 1799\n",
            "(4195, 224, 224, 3) (4195,)\n",
            "(1799, 224, 224, 3) (1799,)\n",
            "Epoch 1/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.0824 - loss: 4.8769 - val_accuracy: 0.2968 - val_loss: 2.9090\n",
            "Epoch 2/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - accuracy: 0.4054 - loss: 2.4658 - val_accuracy: 0.3941 - val_loss: 2.4075\n",
            "Epoch 3/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - accuracy: 0.5613 - loss: 1.8206 - val_accuracy: 0.4314 - val_loss: 2.1950\n",
            "Epoch 4/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - accuracy: 0.6591 - loss: 1.4546 - val_accuracy: 0.4680 - val_loss: 2.0812\n",
            "Epoch 5/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - accuracy: 0.7115 - loss: 1.2083 - val_accuracy: 0.4697 - val_loss: 2.0129\n",
            "Epoch 6/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 1s/step - accuracy: 0.7376 - loss: 1.0757 - val_accuracy: 0.4653 - val_loss: 1.9924\n",
            "Epoch 7/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 1s/step - accuracy: 0.7806 - loss: 0.9311 - val_accuracy: 0.4808 - val_loss: 1.9432\n",
            "Epoch 8/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.8040 - loss: 0.8369 - val_accuracy: 0.4819 - val_loss: 1.9349\n",
            "Epoch 9/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - accuracy: 0.8231 - loss: 0.7794 - val_accuracy: 0.4914 - val_loss: 1.9083\n",
            "Epoch 10/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1s/step - accuracy: 0.8476 - loss: 0.6921 - val_accuracy: 0.4942 - val_loss: 1.9081\n",
            "Epoch 11/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1s/step - accuracy: 0.8675 - loss: 0.6113 - val_accuracy: 0.4908 - val_loss: 1.9107\n",
            "Epoch 12/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - accuracy: 0.8748 - loss: 0.5716 - val_accuracy: 0.4953 - val_loss: 1.9032\n",
            "Epoch 13/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - accuracy: 0.8847 - loss: 0.5271 - val_accuracy: 0.4942 - val_loss: 1.9200\n",
            "Epoch 14/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1s/step - accuracy: 0.9085 - loss: 0.4785 - val_accuracy: 0.5064 - val_loss: 1.8843\n",
            "Epoch 15/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - accuracy: 0.9101 - loss: 0.4425 - val_accuracy: 0.5069 - val_loss: 1.9135\n",
            "Epoch 16/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.9247 - loss: 0.3963 - val_accuracy: 0.5053 - val_loss: 1.9241\n",
            "Epoch 17/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 1s/step - accuracy: 0.9170 - loss: 0.3999 - val_accuracy: 0.5175 - val_loss: 1.8960\n"
          ]
        }
      ],
      "source": [
        "# Load pre-trained Xception model (without top layers)\n",
        "base_model = keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\n",
        "\n",
        "# Add new layers on top\n",
        "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "dropout = keras.layers.Dropout(0.5, noise_shape=None, seed=None)(avg) \n",
        "output = keras.layers.Dense(201, activation=\"softmax\")(dropout)  # 200 classes\n",
        "model = keras.Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Freeze base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)  # Use Adam with a fixed learning rate\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "# Set early stopping\n",
        "earlystopping = callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3, restore_best_weights=True)\n",
        "\n",
        "# Define validation data split at 30%\n",
        "split_idx = int(len(preprocessed_training_images) * 0.7)\n",
        "X_train, X_val = preprocessed_training_images[:split_idx], preprocessed_training_images[split_idx:]\n",
        "y_train, y_val = training_class_label[:split_idx], training_class_label[split_idx:]\n",
        "\n",
        "y_train = np.array(y_train).astype(np.int32)\n",
        "y_val = np.array(y_val).astype(np.int32)\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val), batch_size=32, callbacks=[earlystopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 754ms/step - accuracy: 0.5502 - loss: 1.6985\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.8822968006134033, 0.5146703720092773]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(preprocessed_testing_images, testing_class_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
