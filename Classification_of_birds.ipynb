{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LkAt4xhuz2TP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.xception import preprocess_input\n",
        "from tensorflow.keras import callbacks\n",
        "import keras\n",
        "import keras_tuner\n",
        "import keras.utils as image\n",
        "from keras import layers\n",
        "from keras import ops\n",
        "from keras import callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49L3SjdWR8Oa"
      },
      "source": [
        "## Importing Data from csv files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6Q84PvEJobQu",
        "outputId": "bc83029b-8453-4423-d0da-4b8bab6425dd"
      },
      "outputs": [],
      "source": [
        "images = pd.read_csv(\"/Users/sofie/Desktop/Projects/Classification of Birds/CUB_200_2011/images.txt\", sep=r'\\s+', names=['image_id', 'image_name'], engine='python')\n",
        "train_test_split = pd.read_csv(\"/Users/sofie/Desktop/Projects/Classification of Birds/CUB_200_2011/train_test_split.txt\", sep=r'\\s+', names=['image_id', 'is_training_image'], engine='python')\n",
        "classes =pd.read_csv(\"/Users/sofie/Desktop/Projects/Classification of Birds/CUB_200_2011/classes.txt\", sep=r'\\s+', names=['class_id', 'class_name'], engine='python')\n",
        "image_class_labels =pd.read_csv(\"/Users/sofie/Desktop/Projects/Classification of Birds/CUB_200_2011/image_class_labels.txt\", sep=r'\\s+', names=['image_id', 'class_id'], engine='python')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay9R_UOcSKkH"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Rj27i5GRKG1",
        "outputId": "74981fbd-a7de-43a8-8ffd-76dab7ec4c11"
      },
      "outputs": [],
      "source": [
        "# Merge dfs based on column names so we have one df with all the necessary info contained per each row\n",
        "image_data = pd.merge(images,train_test_split, on='image_id')\n",
        "image_data = pd.merge(image_data,image_class_labels, on='image_id')\n",
        "image_data = pd.merge(image_data,classes, on='class_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split training and testing image data\n",
        "training_image_data = image_data[image_data['is_training_image']==1]\n",
        "testing_image_data = image_data[image_data['is_training_image']==0]\n",
        "\n",
        "# Shuffle training data\n",
        "training_image_data = training_image_data.sample(frac=1)\n",
        "\n",
        "# Initiate empty lists for training and testing images\n",
        "training_images = []\n",
        "testing_images = []\n",
        "\n",
        "# Add training and testing images to corresponding lists\n",
        "for i in (training_image_data['image_name'].values):\n",
        "    training_images.append(image.load_img('/Users/sofie/Desktop/Projects/Classification of Birds/CUB_200_2011/images/{}'.format(i), target_size=(224, 224)))\n",
        "\n",
        "for i in (testing_image_data['image_name'].values):\n",
        "    testing_images.append(image.load_img('/Users/sofie/Desktop/Projects/Classification of Birds/CUB_200_2011/images/{}'.format(i), target_size=(224, 224)))\n",
        "\n",
        "# Extract class labels for training and testing images\n",
        "training_class_label = np.array(training_image_data['class_id'].values)\n",
        "testing_class_label = np.array(testing_image_data['class_id'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert list of images to NumPy array\n",
        "training_images = np.array(training_images)\n",
        "testing_images = np.array(testing_images)\n",
        "\n",
        "# Apply preprocessing\n",
        "preprocessed_training_images = preprocess_input(training_images)\n",
        "preprocessed_testing_images = preprocess_input(testing_images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We begin training by keeping the existing layers frozen, allowing only the newly added classification head to learn. This ensures that the output layer is properly trained before fine-tuning the deeper layers. Once the classifier stabilizes, we gradually unfreeze and fine-tune the earlier layers, optimizing them in a controlled manner. This approach prevents instability in feature extraction and allows each layer to adjust effectively, improving overall model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4195 4195\n",
            "1799 1799\n",
            "(4195, 224, 224, 3) (4195,)\n",
            "(1799, 224, 224, 3) (1799,)\n",
            "Epoch 1/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - accuracy: 0.0085 - loss: 5.3418 - val_accuracy: 0.0311 - val_loss: 5.1121\n",
            "Epoch 2/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 1s/step - accuracy: 0.0517 - loss: 5.0173 - val_accuracy: 0.0856 - val_loss: 4.8626\n",
            "Epoch 3/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1s/step - accuracy: 0.1282 - loss: 4.7261 - val_accuracy: 0.1334 - val_loss: 4.6407\n",
            "Epoch 4/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 1s/step - accuracy: 0.1763 - loss: 4.4809 - val_accuracy: 0.1579 - val_loss: 4.4322\n",
            "Epoch 5/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 1s/step - accuracy: 0.2471 - loss: 4.2336 - val_accuracy: 0.1879 - val_loss: 4.2488\n",
            "Epoch 6/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 1s/step - accuracy: 0.2759 - loss: 4.0322 - val_accuracy: 0.2123 - val_loss: 4.0803\n",
            "Epoch 7/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1s/step - accuracy: 0.3264 - loss: 3.8451 - val_accuracy: 0.2368 - val_loss: 3.9284\n",
            "Epoch 8/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 1s/step - accuracy: 0.3577 - loss: 3.6767 - val_accuracy: 0.2546 - val_loss: 3.7951\n",
            "Epoch 9/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 1s/step - accuracy: 0.3916 - loss: 3.5167 - val_accuracy: 0.2668 - val_loss: 3.6731\n",
            "Epoch 10/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 1s/step - accuracy: 0.4122 - loss: 3.4110 - val_accuracy: 0.2840 - val_loss: 3.5633\n",
            "Epoch 11/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 1s/step - accuracy: 0.4480 - loss: 3.2661 - val_accuracy: 0.2979 - val_loss: 3.4628\n",
            "Epoch 12/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1s/step - accuracy: 0.4565 - loss: 3.1562 - val_accuracy: 0.3152 - val_loss: 3.3724\n",
            "Epoch 13/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1s/step - accuracy: 0.4976 - loss: 3.0077 - val_accuracy: 0.3352 - val_loss: 3.2865\n",
            "Epoch 14/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 1s/step - accuracy: 0.5063 - loss: 2.9534 - val_accuracy: 0.3363 - val_loss: 3.2126\n",
            "Epoch 15/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1s/step - accuracy: 0.5290 - loss: 2.8240 - val_accuracy: 0.3502 - val_loss: 3.1432\n",
            "Epoch 16/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1s/step - accuracy: 0.5437 - loss: 2.7514 - val_accuracy: 0.3602 - val_loss: 3.0799\n",
            "Epoch 17/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1s/step - accuracy: 0.5703 - loss: 2.6430 - val_accuracy: 0.3646 - val_loss: 3.0197\n",
            "Epoch 18/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1s/step - accuracy: 0.5859 - loss: 2.5877 - val_accuracy: 0.3708 - val_loss: 2.9635\n",
            "Epoch 19/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 1s/step - accuracy: 0.5747 - loss: 2.5648 - val_accuracy: 0.3813 - val_loss: 2.9123\n",
            "Epoch 20/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1s/step - accuracy: 0.5990 - loss: 2.4909 - val_accuracy: 0.3919 - val_loss: 2.8660\n",
            "Epoch 21/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1s/step - accuracy: 0.6029 - loss: 2.4252 - val_accuracy: 0.3941 - val_loss: 2.8214\n",
            "Epoch 22/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 1s/step - accuracy: 0.6114 - loss: 2.3820 - val_accuracy: 0.3980 - val_loss: 2.7785\n",
            "Epoch 23/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 1s/step - accuracy: 0.6192 - loss: 2.2996 - val_accuracy: 0.4019 - val_loss: 2.7399\n",
            "Epoch 24/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 1s/step - accuracy: 0.6280 - loss: 2.2675 - val_accuracy: 0.4074 - val_loss: 2.7045\n",
            "Epoch 25/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 1s/step - accuracy: 0.6341 - loss: 2.2239 - val_accuracy: 0.4086 - val_loss: 2.6725\n",
            "Epoch 26/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 1s/step - accuracy: 0.6484 - loss: 2.1709 - val_accuracy: 0.4113 - val_loss: 2.6395\n",
            "Epoch 27/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733ms/step - accuracy: 0.6478 - loss: 2.1577"
          ]
        }
      ],
      "source": [
        "# Load pre-trained Xception model (without top layers)\n",
        "base_model = keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\n",
        "\n",
        "# Add new layers on top\n",
        "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "dropout = keras.layers.Dropout(0.5, noise_shape=None, seed=None)(avg) \n",
        "output = keras.layers.Dense(201, activation=\"softmax\")(dropout)  # 200 classes\n",
        "model = keras.Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Freeze base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Learning rate schedule\n",
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,  # Lower LR for stability\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9\n",
        ")\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "\n",
        "# Set early stopping\n",
        "earlystopping = callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3, restore_best_weights=True)\n",
        "\n",
        "# Define validation data split at 30%\n",
        "split_idx = int(len(preprocessed_training_images) * 0.7)\n",
        "X_train, X_val = preprocessed_training_images[:split_idx], preprocessed_training_images[split_idx:]\n",
        "y_train, y_val = training_class_label[:split_idx], training_class_label[split_idx:]\n",
        "\n",
        "y_train = np.array(y_train).astype(np.int32)\n",
        "y_val = np.array(y_val).astype(np.int32)\n",
        "\n",
        "print(len(X_train), len(y_train))\n",
        "print(len(X_val), len(y_val))\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val), batch_size=32, callbacks=[earlystopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1003s\u001b[0m 5s/step - accuracy: 0.6479 - loss: 1.9867\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[4.9380340576171875, 0.42716604471206665]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(preprocessed_testing_images[0], preprocessed_testing_images[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    brightness_range=None,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.3,\n",
        "    fill_mode='nearest',\n",
        "    cval=0.0,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    rescale=None,\n",
        "    preprocessing_function=Preprocess(),\n",
        "    validation_split=0.4,\n",
        ")\n",
        "\n",
        "'''img = load_img('data/train/cats/cat.0.jpg')  # this is a PIL image\n",
        "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
        "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
        "'''\n",
        "# the .flow() command below generates batches of randomly transformed images\n",
        "# and saves the results to the `preview/` directory\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=1,\n",
        "                          save_to_dir='preview', save_prefix='cat', save_format='jpeg'):\n",
        "    i += 1\n",
        "    if i > 20:\n",
        "        break  # otherwise the generator would loop indefinitely"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
